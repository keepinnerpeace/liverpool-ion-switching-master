在我开始描述我的方法之前，我想感谢以下kaggler:
1、@eunholee发现了最有效的消除漂移的方法，解释在这个内核。

2、@friedchips非常深入地研究了数据的马尔可夫性质。他的帖子
和内核激励我学习更多关于HMM的知识(这在最后几周的比赛中并
没有帮助我，但我体验到了学习这个主题的真正乐趣)。

3、@kakoimasataka让我注意到数据的噪音成分。他的核让我明白在预处理中应该如何处理噪声。

我在早期阶段承认了以下几点:

1、与模型调优相比，预处理和数据扩充对最终得分的贡献更大。这项比赛的早期突破之一是漂移去除。

2、在0.935+区域，即使是非常微不足道的(小数点后5或6个符号)分数的提高(CV或LB)也是重要的，应该加以考虑。


一、预处理和数据泄漏

我在这里描述了数据清理和创建新数据的过程。不幸的是，测试数据集的私有部分因泄漏而损坏。
其他团队已经在这篇文章中透露过了，所以我就不在这里描述了。下面是我的个人经历。
用我创建新数据的方式，我在我的本地简历中面临这个泄漏，我必须与它斗争(我将在建模部分解释如何)，
以获得可靠的简历分数。在比赛结束前不到两天，我检查了这种泄漏的测试数据。
结果让我震惊:我从来没有想过我能在私处找到它!

二、建模

作为我最终模型的基线，我使用了基于wavenet的体系结构，它最初发布在这个内核中。以下想法对我很有效:

1、早期停止，学习速率调度。对于不同的折叠，我的模型的收敛行为略有不同，所以这些简单的
工具帮助我控制过拟合。

2、数据增强。我用翻转信号，然后给信号加一个随机移位。实验表明，模型的预测对移动非常敏感，
这种增强帮助模型变得更加一般化。

3、RFC的输出作为NN的输入特征。最初在这篇文章中提出，这种堆叠的有效性已经在我的实验中得到了证实。

4、交叉验证的策略。当我使用不同的增强数据集(具有不同的大小和目标分布)进行训练时，
我必须在子数据集上进行验证，这对于所有合成数据集都是常见的。为此，我选择了原始的非合成数据。
在这个子集上获得的OOF分数用于比较不同的模型，这些模型可能使用不同的数据进行训练。
原始训练数据没有被上面提到的泄露破坏，所以它是安全的，而且我在比赛截止日期后才知道，它与私人LB有关。

5、一个模型适用于所有数据组。对于基于nn的模型，不需要针对不同的群体训练不同的模型。
此外，我观察到组之间的某种协同作用:单独的模型比一个通用模型具有更低的CV。

三、最后提交
我的第一个提交是两个模型的混合，用稍微不同的标量和增强训练。这里没有泄漏，
这个提交在我发现泄漏之前就计划好了。CV 0.94359，公共0.94664，私人LB 0.94529。

第二份与第一份的差异仅在第7批测试数据。为了预测这批数据，我训练了一个单独的减少信号模型，
然后在其预测中添加减法通道。


四、结论
我对这场比赛百感交集。
一方面，我还没有建立一个可以处理真实离子交换数据的模型。目前发表的其他解决方案也几乎
不适用于与竞争数据集不同的数据。例如，漂移问题还没有解决，所有的高分模型都是在干净的
数据上训练的。我在最后几天的比赛中发现的漏洞让人对数据失去了信心。我意识到这种泄漏可
以隐式地隐藏在其余数据中，因此复杂的模型可以自动利用它。

另一方面，我努力工作了一个半月多，享受我的模型的改进，这真的很有趣和酷。关于泄露，
我认为搜索数据漏洞的任务本身是有价值的。从长远来看，它可以帮助建立可靠的模型。
我不能肯定，但可能离子交换数据可能泄露的知识将帮助电生理学家改进他们现有的模型。