1、综述

我的最终模型是随机森林 (RFC) 和基于 Wavenet 的神经网络架构的堆叠。
 RFC 模型最重要的特征是信号滞后和超前。 Wavenet 模型接受 RFC 预测
和具有低阶滞后和超前的纯信号作为特征。 对于 RFC 模型，
我使用了 Sklearn 实现。 Wavenet 是在带有 Tensorflow 后端
的 Keras 中实现的。 训练整个管道大约需要一天时间。 预测可以更快地完成
——在竞赛测试数据集上大约需要 10 分钟。

2、预处理步骤
去趋势信号 

数据中添加了合成漂移。 为了训练我的模型，
我使用了 Chris Deotte 的惊人的去趋势数据集。

对齐平均信号值
 
数据可以分为6组，对应不同的生成模型。
 其中之一仅出现在测试数据集中。 第三组的平均值与其他组不一致。 
对齐这些值提高了最终模型的质量。

移除异常值 

第 7 批训练数据被奇怪的噪声尖峰破坏。
我用来自同一个生成模型的另一个噪声样本替换了这个片段。

创建更多数据 
通过汇总开放通道值和相应的噪声样本，可以从现有数据中创建新数据。
我在这个笔记本的所有细节中描述了这个过程

3、特征工程

在这场比赛中，滞后和领先特征具有重要意义。 解释是每个离子通道的
打开/关闭状态往往在短时间内保持不变。 例如，如果在特定时刻打开了
N 个通道，则下一步更有可能还有 N 个打开的通道。

在图片中，您可以看到添加一个滞后特征有助于更有效地拆分数据。
使用这种特征对于基于树的模型非常重要。

使用滚动统计数据时（尤其是大间隔）应该非常小心。这些功能可能会泄漏，
需要彻底的验证方法来解决所有可能的泄漏问题。

4、训练方法

第一层堆叠：RFC 为了训练随机森林，我使用了 1x5 交叉验证方案，
并按训练信号批次进行分层：
cv = StratifiedKFold(n_splits=n_splits).split(train, train.index // strat_int)
折叠（OOF）预测被传递到下一层堆叠。 对测试数据的预测是每个折叠对应的5个模型的混合。

第二层堆叠：Wavenet Wavenet 在长度为 4000 的信号序列上进行训练，
RFC OOF 预测作为特征传递。 我使用了 1x5 GroupKFold 验证方案：
cv = GroupKFold(n_splits=n_splits).split(火车，火车[目标]，组)

为了改进模型，我实现了以下在线数据增强：信号翻转、随机移位、
周期性 50 Hz 噪声和高斯噪声。 OOF 预测用于评估一般模型质量。
对测试数据的最终预测是每个折叠对应的5个模型的混合。

集成的目的

在我的实验中，我发现基于树和基于波网的模型的错误仅在大约80%的情况下重叠。
这意味着神经网络能够纠正基于树的模型的错误，反之亦然。

方法的优点。

所提出方法的主要优点是所有数据组仅使用一个模型。 
在训练阶段不需要手动分割数据。

5 有趣的发现
我在比赛中使用的关键技巧是上面描述的新数据创建。它极大地提升了我所有的模型。
另一个技巧是我在比赛最后几天暴露的数据泄露。 已经在这篇文章中透露了。
总的来说，预处理策略是比赛的关键，它对最终得分的贡献最大。

6 如何简化模型？

如果你在没有 RFC 预测的情况下训练纯波网模型，它会稍微降低性能，
但测试数据集的最终质量仍将在 0.942 左右。 您还可以减少验证折叠
的数量并训练更少的模型。

7 模型执行时间和最终分数

在我在 README.md 中详述的硬件上运行包括所有堆叠层在内的整个
管道大约需要一天时间。 做出预测要快得多：完整的测试数据集大约
需要 10 分钟。 简化模型使事情变得越来越容易。
在这种情况下，训练将需要几个小时。此存储库中提供的模型在未利用
泄漏的情况下在私有 LB 上达到 0.94535，在利用泄漏的情况下达到 0.95356。